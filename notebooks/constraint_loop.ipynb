{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NextActivityPredictor(\n",
       "  (embedding): Embedding(40, 128, padding_idx=0)\n",
       "  (lstm): LSTM(128, 128, batch_first=True)\n",
       "  (fc): Linear(in_features=128, out_features=40, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pathlib\n",
    "\n",
    "import torch\n",
    "\n",
    "from pylon_experiments.model.model import NextActivityPredictor, Args\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "checkpoint = pathlib.Path(\"../runs/bpic2012/20250212.2112.no_constraint/model.best_val_loss.pth\")\n",
    "model = torch.load(checkpoint, weights_only=False).to(torch.device(\"cpu\"))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpylon_experiments\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Loader, Args \u001b[38;5;28;01mas\u001b[39;00m LoaderArgs\n\u001b[0;32m----> 5\u001b[0m train, val \u001b[38;5;241m=\u001b[39m Loader(args\u001b[38;5;241m=\u001b[39mLoaderArgs(\n\u001b[1;32m      6\u001b[0m     dataset_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/bpic2012\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m      8\u001b[0m ))\u001b[38;5;241m.\u001b[39mget_loaders()\u001b[38;5;241m.\u001b[39mvalues()\n\u001b[1;32m     10\u001b[0m train\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "from pylon_experiments.data.loader import Loader, Args as LoaderArgs\n",
    "\n",
    "train, val = Loader(args=LoaderArgs(\n",
    "    dataset_path=\"../data/bpic2012\",\n",
    "    batch_size=2,\n",
    ")).get_loaders().values()\n",
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'dict_values' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mloaders\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'dict_values' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "loaders[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pylon_experiments.data.log_dataset.LogDataset object at 0x7da419f03f50>\n",
      "(tensor([2]), tensor(4), tensor(1))\n",
      "<pylon_experiments.data.log_dataset.LogDataset object at 0x7da419f03dd0>\n",
      "(tensor([2]), tensor(4), tensor(1))\n",
      "<pylon_experiments.data.log_dataset.LogDataset object at 0x7da419aab280>\n",
      "(tensor([2]), tensor(4), tensor(1))\n",
      "<pylon_experiments.data.trace_dataset.TraceDataset object at 0x7da416a88290>\n",
      "(tensor([ 2,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 16, 17, 16,\n",
      "        17, 16, 17, 16, 17, 16, 17, 16, 17, 16, 36, 26, 17,  3]), tensor(32, dtype=torch.uint8))\n",
      "<pylon_experiments.data.trace_dataset.TraceDataset object at 0x7da416a88350>\n",
      "(tensor([ 2,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 16, 18, 19,\n",
      "        17, 20, 25, 20, 30, 25, 31, 32, 31, 19, 32, 20, 21, 22, 24, 23, 25,  3]), tensor(36, dtype=torch.uint8))\n",
      "<pylon_experiments.data.trace_dataset.TraceDataset object at 0x7da419aab330>\n",
      "(tensor([ 2,  4,  5,  6,  7,  8,  9, 11, 10, 12, 13, 14, 15, 16, 17, 16, 17, 16,\n",
      "        26, 36, 17,  3]), tensor(22, dtype=torch.uint8))\n"
     ]
    }
   ],
   "source": [
    "for l in loaders:\n",
    "    print(l.dataset)\n",
    "    print(l.dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/234 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[error][len: 6] [2 4 5 6 7 8] -> 15 (9)\n",
      "[correct][len: 6] [2 4 5 6 7 8] -> 15 (15)\n",
      "tensor(False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'argmacx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([x, logits\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28mprint\u001b[39m((logits[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m trace[\u001b[38;5;241m0\u001b[39m, i]))\n\u001b[0;32m---> 28\u001b[0m     total_correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[43mlogits\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmacx\u001b[49m(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m trace[:, i])\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     29\u001b[0m     total_samples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(trace)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'argmacx'"
     ]
    }
   ],
   "source": [
    "from itertools import zip_longest\n",
    "\n",
    "\n",
    "loader = tqdm(\n",
    "    loaders[4],\n",
    "    unit=\"batch\",\n",
    "    bar_format=\"{l_bar}{bar:10}{r_bar}{bar:-10b}\",\n",
    ")\n",
    "\n",
    "count = 0\n",
    "total_correct = 0\n",
    "total_samples = 0\n",
    "for trace, lengths in loader:\n",
    "    batch_logits = []\n",
    "\n",
    "    x = trace[:, :6]\n",
    "    for i in range(6, lengths[0]):\n",
    "        lengths = torch.tensor([i] * len(x))\n",
    "        logits = model(x, lengths)\n",
    "        batch_logits.append(logits)\n",
    "        for j in range(len(x)):\n",
    "            correct = logits[j].argmax(dim=-1) == trace[j, i]\n",
    "            correct = 'correct' if correct else 'error'\n",
    "            print(f\"[{correct}][len: {lengths[j].item()}] {x[j].numpy()} -> {logits.argmax(dim=-1)[j]} ({trace[j, i].item()})\")\n",
    "        x = torch.cat([x, logits.argmax(dim=1, keepdim=True)], dim=1)\n",
    "        \n",
    "        print((logits[0].argmax(dim=-1) == trace[0, i]))\n",
    "        total_correct += (logits.argmacx(dim=-1) == trace[:, i]).sum().item()\n",
    "        total_samples += len(trace)\n",
    "    break\n",
    "        \n",
    "\n",
    "print(total_correct / total_samples)            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
